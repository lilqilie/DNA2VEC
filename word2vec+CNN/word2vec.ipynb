{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unable to import 'smart_open.gcs', disabling that module\n",
      "F:\\anaconda\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\utils\\fixes.py:313: FutureWarning: numpy not_equal will not check object identity in the future. The comparison did not return the same result as suggested by the identity (`is`)) and will change.\n",
      "  _nan_object_mask = _nan_object_array != _nan_object_array\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import random\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.word2vec import LineSentence\n",
    "import warnings\n",
    "from sklearn import preprocessing\n",
    "import sklearn.preprocessing\n",
    "from gensim import corpora, models, similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getWord_model(word,num_features,min_count, model, Unfile):\n",
    "\tword_model = \"\"\n",
    "\tif not os.path.isfile(model):\n",
    "\t\tsentence = LineSentence(Unfile,max_sentence_length = 15000)\n",
    "\n",
    "\t\tnum_features = int(num_features)\n",
    "\t\tmin_word_count = int(min_count)\n",
    "\t\tnum_workers = 20\n",
    "\t\tcontext = 20\n",
    "\t\tdownsampling = 1e-3\n",
    "\n",
    "\t\tprint (\"Training Word2Vec model...\")\n",
    "\t\tword_model = Word2Vec(sentence, workers=num_workers,\\\n",
    "\t\t\t\t\t\tsize=num_features, min_count=min_word_count, \\\n",
    "\t\t\t\t\t\twindow=context, sample=downsampling, seed=1,iter = 50)\n",
    "\t\tword_model.init_sims(replace=False)\n",
    "\t\tword_model.save(model)\n",
    "\n",
    "\telse:\n",
    "\t\tprint (\"Loading Word2Vec model...\")\n",
    "\t\tword_model = Word2Vec.load(model)\n",
    "\n",
    "\treturn word_model\n",
    "\n",
    "def DNAToWord(dna, K):\n",
    "\n",
    "\tsentence = \"\"\n",
    "\tlength = len(dna)\n",
    "\n",
    "\tfor i in range(length - K + 1):\n",
    "\t\tsentence += dna[i: i + K] + \" \"\n",
    "\n",
    "\tsentence = sentence[0 : len(sentence) - 1]\n",
    "\treturn sentence\n",
    "\n",
    "\n",
    "def getDNA_split(DNAdata,word):\n",
    "\n",
    "\tlist1 = []\n",
    "\tlist2 = []\n",
    "\tfor DNA in DNAdata[\"seq1\"]:\n",
    "\t\tDNA = str(DNA).upper()\n",
    "\t\tlist1.append(DNAToWord(DNA,word).split(\" \"))\n",
    "\n",
    "\tfor DNA in DNAdata[\"seq2\"]:\n",
    "\t\tDNA = str(DNA).upper()\n",
    "\t\tlist2.append(DNAToWord(DNA,word).split(\" \"))\n",
    "\n",
    "\treturn list1,list2\n",
    "\n",
    "def getAvgFeatureVecs(DNAdata1,DNAdata2,model,num_features):\n",
    "\tcounter = 0\n",
    "\tDNAFeatureVecs = np.zeros((len(DNAdata1),2*num_features), dtype=\"float32\")\n",
    "\t\n",
    "\tfor DNA in DNAdata1:\n",
    "\t\tif counter % 1000 == 0:\n",
    "\t\t\tprint (\"DNA %d of %d\\r\" % (counter, len(DNAdata1)))\n",
    "\t\t\tsys.stdout.flush()\n",
    "\n",
    "\t\tDNAFeatureVecs[counter][0:num_features] = np.mean(model[DNA],axis = 0)\n",
    "\t\tcounter += 1\n",
    "\tprint()\n",
    "\t\n",
    "\tcounter = 0\n",
    "\tfor DNA in DNAdata2:\n",
    "\t\tif counter % 1000 == 0:\n",
    "\t\t\tprint (\"DNA %d of %d\\r\" % (counter, len(DNAdata2)))\n",
    "\t\t\tsys.stdout.flush()\n",
    "\t\tDNAFeatureVecs[counter][num_features:2*num_features] = np.mean(model[DNA],axis = 0)\n",
    "\t\tcounter += 1\n",
    "\n",
    "\treturn DNAFeatureVecs\n",
    "\n",
    "def npyTosvm(npyfile, svmfile, pos_num):\n",
    "\tdataDataVecs = np.load(npyfile)\n",
    "\tg = open(svmfile,'w')\n",
    "\tprint(len(dataDataVecs))\n",
    "\t#print(dataDataVecs[0])\n",
    "\tm = 0\n",
    "\tfor i in range(len(dataDataVecs)):\n",
    "\t\tline = ''\n",
    "\t\tfor j in range(len(dataDataVecs[0])):\n",
    "\t\t\tif j == len(dataDataVecs[0])-1:\n",
    "\t\t\t\tline += str(j+1)+':'+str(dataDataVecs[i][j])+'\\n'\n",
    "\t\t\telse:\n",
    "\t\t\t\tline += str(j+1)+':'+str(dataDataVecs[i][j])+'\\t'\n",
    "\t\tm += 1\n",
    "\t\tif m < (pos_num+1):\n",
    "\t\t\tg.write('1\\t'+line)\n",
    "\t\telse:\n",
    "\t\t\tg.write('0\\t'+line)\n",
    "\n",
    "def SVMtoCSV(svmfile, csvfile):\n",
    "\tf = open(svmfile,'r')\n",
    "\tg = open(csvfile,'w')\n",
    "\tlines = f.readlines()\n",
    "\tlegth = len(lines[0].split('\t'))-1\n",
    "\t#print(legth)\n",
    "\tclassline = 'class'\n",
    "\tfor i in range(legth):\n",
    "\t\tclassline += ',%d'%(i+1)\n",
    "\tg.write(classline+'\\n')\n",
    "\n",
    "\tfor line in lines:\n",
    "\t\tline = line.strip('\\n').split('\t')\n",
    "\t\tg.write(line[0]+',')\n",
    "\n",
    "\t\tlegth2 = len(line[1:])\n",
    "\t\tm = 0\n",
    "\t\tfor j in line[1:]:\n",
    "\t\t\tif m == legth2-1:\n",
    "\t\t\t\tj = j.split(':')[-1]\n",
    "\t\t\t\tg.write(j)\n",
    "\t\t\t\tm += 1\n",
    "\t\t\telse:\n",
    "\t\t\t\tj = j.split(':')[-1]\n",
    "\t\t\t\tg.write(j+',')\n",
    "\t\t\t\tm += 1\n",
    "\t\tg.write('\\n')\n",
    "\n",
    "\tf.close()\n",
    "\tg.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Word2Vec model...\n",
      "DNA 0 of 20\n",
      "\n",
      "DNA 0 of 20\n",
      "(20, 200)\n",
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\anaconda\\anaconda\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:58: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "F:\\anaconda\\anaconda\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:67: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    }
   ],
   "source": [
    "kmer = 3\n",
    "seqfile = 'test.fa'\n",
    "pos_number = 10 # NOTE: the number of postive sample in test file\n",
    "\n",
    "#### generate Unsupervised ##### \n",
    "Unfile = '%dUn'%(kmer)\n",
    "g = open(Unfile,'w')\n",
    "DNAseq = pd.read_csv(seqfile,sep = \"\\t\",error_bad_lines=False)\n",
    "words1,words2 = getDNA_split(DNAseq,kmer)\n",
    "\n",
    "for i in range(len(words1)):\n",
    "\tline = ' '.join(words1[i])\n",
    "\tg.write(line+'\\n')\n",
    "\n",
    "for i in range(len(words2)):\n",
    "\tline = ' '.join(words2[i])\n",
    "\tg.write(line+'\\n')\n",
    "g.close()\n",
    "\n",
    "#####get word2vec model#####\n",
    "model = 'model_%d'%(kmer)\n",
    "fea_num = 100\n",
    "min_fea = 10\n",
    "getWord_model(kmer,fea_num,min_fea,model,Unfile)\n",
    "\n",
    "####obtain word2vec feature set####\n",
    "\n",
    "word_model = Word2Vec.load(model)\n",
    "dataDataVecs = getAvgFeatureVecs(words1,words2,word_model,fea_num)\n",
    "print (dataDataVecs.shape)\n",
    "fea_npy = '%d_vecs.npy'%(kmer)\n",
    "np.save(fea_npy,dataDataVecs)\n",
    "\n",
    "\n",
    "#### npy To csv #####\n",
    "fea_svm = '%d_vecs.svm'%(kmer)\n",
    "fea_csv = '%d_vecs.csv'%(kmer)\n",
    "\n",
    "npyTosvm(fea_npy, fea_svm,pos_number)\n",
    "SVMtoCSV(fea_svm, fea_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
